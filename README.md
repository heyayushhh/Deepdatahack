# ğŸ” Demand Forecasting with Machine Learning

## ğŸš€ Overview

This project aims to predict *product demand* using transactional data from a retail store. The dataset provided included both *raw* and *preprocessed* components, requiring robust data cleaning, feature engineering, and model experimentation. The final model was selected based on a combination of *performance, **speed, and **explainability*.

---

## ğŸ“ Dataset Description

- Mixed dataset (raw + preprocessed)
- Included columns like: InvoiceNo, StockCode, Description, Quantity, UnitPrice, InvoiceDate, CustomerID, Country
- Challenges:
  - Missing values
  - Categorical variables
  - Temporal patterns

---

## ğŸ§¹ Data Preprocessing

- Converted InvoiceDate to datetime
- Imputed missing:
  - Description â†’ "Unknown"
  - CustomerID â†’ -1
- Removed irrelevant columns (e.g. InvoiceNo, Country)
- Engineered features:
  - TotalPrice = Quantity Ã— UnitPrice
  - Month, Day, Hour, Weekday
- Aggregated data per product and date

---

## ğŸ§  Models Tried

| Model         | RMSE     | RÂ² Score | Notes                             |
|---------------|----------|----------|-----------------------------------|
| XGBoost       | ~68.5    | ~0.31    | Slow, slightly lower performance  |
| Random Forest | *67.31| **0.33* | Chosen model â€“ faster & explainable   |

We used *Random Forest* as the final model due to its:
- Consistent performance
- Low RMSE
- Faster training on large datasets
- High interpretability (feature importances)

---

## ğŸ§ª Evaluation Metrics

- *RMSE*: 67.31
- *RÂ² Score*: 0.33
- Feature Importance Plots
- Actual vs. Predicted Quantity Scatter Plot

*Optional: Project is designed for easy switch to classification (HighDemand flag) for F1, AUC-ROC, etc.*

---

## ğŸ“Š Model Explainability

We used:
- ğŸ”¥ *Feature Importance* from Random Forest
- ğŸ§¬ (Optional) SHAP for model insights

---

## ğŸ† Why This Project Stands Out

âœ… Clean data processing pipeline  
âœ… Smart feature engineering  
âœ… Model selection based on actual test metrics  
âœ… Explainability and visuals for trust  
âœ… Ready-to-deploy code structure  
âœ… Fully reproducible with a single notebook

---

## ğŸ›  Tech Stack

- *Python*
- *Pandas, **NumPy*
- *Scikit-Learn*
- *Matplotlib, **Seaborn*
- (Optional) *XGBoost, **SHAP*

---

## ğŸ“Œ Judging Criteria Coverage

| Criteria                    | âœ… Done |
|-----------------------------|--------|
| Data Preprocessing          | âœ… Yes |
| Feature Engineering         | âœ… Yes |
| Multiple Model Evaluation   | âœ… Yes |
| Model Explainability        | âœ… Yes |
| Visualizations              | âœ… Yes |
| Reproducible Code           | âœ… Yes |
| F1, AUC Ready (optional)    | âœ… Prepared for switch |
| Innovation                  | âœ… Custom features + smart choices |

---

## ğŸ”— Submission

- *Source Code*: [GitHub Repo Link](https://github.com/your-repo-here)
- *Final Notebook*: final_model.ipynb
- *Presentation*: [Available separately]

---

## ğŸ“¬ Contact

For any questions or issues, open an issue or contact your-ayushkrsna01@gmail.com.

---
